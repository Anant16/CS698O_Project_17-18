{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Custom Networks\n",
    "In this notebook you have to create a custom network whose architecture has been given, and use the dataset you created earlier to train and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "#\n",
    "# Several of the imports you will need have been added but you will need to provide the\n",
    "# rest yourself; you should be able to figure out most of the imports as you go through\n",
    "# the notebook since without proper imports your code will fail to run\n",
    "#\n",
    "# All import statements go in this block\n",
    "\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from PIL import Image\n",
    "import unicodedata\n",
    "from IPython import display\n",
    "import time\n",
    "\n",
    "import numpy.linalg as LA\n",
    "import cv2\n",
    "# from matplotlib.mlab import PCA\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "use_gpu = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All hyper parameters go in the next block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_epochs = 20\n",
    "learning_rate = 0.01\n",
    "reg_lambda = 0.0000003\n",
    "crop_res = (112, 112)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "windowStride = (16,16)\n",
    "\n",
    "# winSize = (40, 40)\n",
    "# blockSize = (20,20)\n",
    "# blockStride = (10,10)\n",
    "# cellSize = (5,5)\n",
    "\n",
    "winSize = (40,40)#(image_size[0]/2,image_size[1]/2)\n",
    "blockSize = (20,20)\n",
    "blockStride = (10,10)\n",
    "cellSize = (5,5)\n",
    "nbins = 9\n",
    "derivAperture = 1\n",
    "winSigma = 4.\n",
    "histogramNormType = 0\n",
    "L2HysThreshold = 2.0000000000000001e-01\n",
    "gammaCorrection = 0\n",
    "nlevels = 64\n",
    "\n",
    "hog_size = 1296 # as observed\n",
    "num_data_patches = 66920\n",
    "num_patches_per_image = 25\n",
    "\n",
    "Wt_ir = np.identity(hog_size)\n",
    "Wt_vi = np.identity(hog_size)\n",
    "mu_ir = 0\n",
    "mu_vi = 0\n",
    "data_mean = 0\n",
    "pca_dims = 1296\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    #image is np.array\n",
    "    # \timage_size = (80, 100)\n",
    "    #image = cv2.resize(image, image_size)\n",
    "    # median blur/filter\n",
    "    median_blur_amount = 1\n",
    "    image = cv2.medianBlur(image, median_blur_amount)\n",
    "    # zero mean normalize\n",
    "    norm_im = image.astype(np.float32)\n",
    "    norm_im = (norm_im - norm_im.mean()) / norm_im.std() #zero mean unit variance\n",
    "    # DOG\n",
    "    g_blur_tuple = (5,5)\n",
    "    g_blur_amount1 = 1.0\n",
    "    g_blur_amount2 = 0.5\n",
    "    begin_blur = time.time()\n",
    "    gblur1 = cv2.GaussianBlur(norm_im, g_blur_tuple, g_blur_amount1)\n",
    "    gblur2 = cv2.GaussianBlur(norm_im, g_blur_tuple, g_blur_amount2)\n",
    "    image_dog = gblur2 - gblur1\n",
    "#     print(\"image_dog\")\n",
    "#     print(image_dog)\n",
    "    end_blur = time.time()\n",
    "#     print(\"Time to get GaussBlur was \" + str(end_blur - begin_blur))\n",
    "    # HOG Descriptors:\n",
    "   \n",
    "    img = image_dog*255\n",
    "    img = np.array(img, dtype=np.uint8)\n",
    "#     print(\"img shape\")\n",
    "#     print(img.shape)\n",
    "#     print(img)\n",
    "#     nbins = 9\n",
    "#     derivAperture = 1\n",
    "#     winSigma = 4.\n",
    "#     histogramNormType = 0\n",
    "#     L2HysThreshold = 2.0000000000000001e-01\n",
    "#     gammaCorrection = 0\n",
    "#     nlevels = 64\n",
    "    begin_hog = time.time() # hog\n",
    "    hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,\n",
    "                            histogramNormType,L2HysThreshold,gammaCorrection,nlevels)\n",
    "    #compute(img[, winStride[, padding[, locations]]]) -> descriptors\n",
    "    winStride = (8,8)\n",
    "    padding = (8,8)\n",
    "#     locations = ((winSize[0]/2,winSize[1]/2),)\n",
    "    locations = ((0,0),)\n",
    "#     print(\"locations \" + str(locations))\n",
    "#     print(\"winst\" + str(winStride))\n",
    "    hist = hog.compute(img,winStride,padding, locations)\n",
    "#     print(hist.size)\n",
    "#     print(hist)\n",
    "    end_hog = time.time() #hog\n",
    "#     print(\"Time to get hog was \" + str(end_hog - begin_hog))\n",
    "#     print(\"hist size\" + str(hist.shape))\n",
    "    return np.transpose(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def computePCA(  train=True):\n",
    "    \n",
    "#     root_dir = \"./images\"\n",
    "#     if(train == True):\n",
    "#             rd_walk = root_dir + \"/train/Visible\"\n",
    "#     else:\n",
    "#         rd_walk = root_dir + \"/test\"\n",
    "#     ir_projs = np.zeros((1,winSize[0], winSize[1]))\n",
    "#     vi_projs = np.zeros((1,winSize[0], winSize[1]))\n",
    "#     file_map = list()\n",
    "#     rd = root_dir + \"/train/\"\n",
    "#     i=0\n",
    "#     j=0\n",
    "#     vi_projs = np.zeros((num_data_patches, hog_size))\n",
    "#     ir_projs = np.zeros((num_data_patches, hog_size))\n",
    "#     begin_walk = time.time()\n",
    "#     for subdir, dirs, files in os.walk(rd_walk):\n",
    "#         for File in files:\n",
    "#             print(str(i) + \"\\t\\t\" + File)\n",
    "#             i = i+1\n",
    "#             lab = int(File.split('_')[0])  \n",
    "#             (x, y, w, h) = (int(File.split('_')[1]), int(File.split('_')[2]), int(File.split('_')[3]), int(File.split('_')[4]))              \n",
    "#             file_map = file_map + [(File, lab, (x, y, w, h))]\n",
    "            \n",
    "#             ir_img = Image.open(rd + \"Infrared/\" + File).convert('RGB')\n",
    "#             vi_img = Image.open(rd + \"Visible/\" + File).convert('RGB')\n",
    "#             ir_img = np.array(ir_img)\n",
    "#             vi_img = np.array(vi_img)\n",
    "#             ir_img = ir_img[y: y+h, x: x+w]\n",
    "#             vi_img = vi_img[y: y+h, x: x+w]\n",
    "#             ir_img = np.resize(ir_img, crop_res)\n",
    "#             vi_img = np.resize(vi_img, crop_res)\n",
    "\n",
    "\n",
    "#             stride_1 = windowStride[0]\n",
    "#             stride_2 = windowStride[1]\n",
    "#             point_set = set((a,b) for a in range(0,crop_res[1] - winSize[1], stride_1) for b in range(0,crop_res[0] - winSize[0],stride_2))\n",
    "#             print(\"point set len is \"+str(len(point_set)))\n",
    "            \n",
    "#             begin_patching = time.time()\n",
    "#             for cx,cy in point_set:\n",
    "#                 area = (cy, cx, cy + winSize[0], cx + winSize[1])\n",
    "#                 # area_set = area_set + [area]\n",
    "#                 ir_patch = ir_img[cy:cy+winSize[0], cx:cx+winSize[1]]\n",
    "#                 vi_patch = vi_img[cy:cy+winSize[0], cx:cx+winSize[1]]\n",
    "#                 ir_hog = preprocessing(ir_patch) #return row vector\n",
    "#                 vi_hog = preprocessing(vi_patch)\n",
    "#                 ir_projs[j] = ir_hog\n",
    "#                 vi_projs[j] = vi_hog\n",
    "#                 j=j+1\n",
    "# #                 ir_projs = np.append(ir_hog, ir_projs)\n",
    "# #                 vi_projs = np.append(vi_hog, vi_projs)\n",
    "# #                 print(ir_projs.shape, ir_hog.shape)\n",
    "# #                 ir_patch = np.reshape(ir_patch, (1,winSize[0], winSize[1]))\n",
    "# #                 vi_patch = np.reshape(vi_patch, (1,winSize[0], winSize[1]))\n",
    "                \n",
    "# #                 ir_projs = np.concatenate((ir_projs, ir_patch), axis=0)  # the most expensive process\n",
    "# #                 vi_projs = np.concatenate((vi_projs, vi_patch), axis=0)\n",
    "#             end_patching = time.time()\n",
    "# #             print(\"time to make patches: \" + str(end_patching - begin_patching))\n",
    "#     end_walk = time.time()\n",
    "#     print(\"Toatal walk in files time: \" + str(end_walk - begin_walk))\n",
    "#     print(j)\n",
    "#     print(\"Now Computing PCA for ir\")\n",
    "#     print(np.isfinite(ir_projs).all())\n",
    "# #     result = PCA(ir_projs, standardize=False)\n",
    "#     pca_ir = PCA(n_components = 64)\n",
    "#     pca_ir.fit(ir_projs)\n",
    "#     print(pca_ir.components_)\n",
    "# #     Wt_ir = result.Wt\n",
    "# #     mu_ir = result.mu\n",
    "# #     print(Wt_ir)\n",
    "#     print(\"Now Computing PCA for vi\")\n",
    "    \n",
    "#     pca_vi = PCA(n_components = 64)\n",
    "#     pca_vi.fit(vi_projs)\n",
    "#     print(pca_vi.components_)\n",
    "# #     result = PCA(vi_projs, standardize=False)\n",
    "#     print(\"Done PCA!\")\n",
    "# #     Wt_vi = result.Wt\n",
    "# #     mu_vi = result.mu\n",
    "# #     print(Wt_vi)\n",
    "#     return ( Wt_ir, Wt_vi, mu_ir, mu_vi) \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%time ( Wt_ir, Wt_vi, mu_ir, mu_vi) =  computePCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(Wt_ir)\n",
    "# print(Wt_vi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Custom Dataset and Loader\n",
    "This is the same as part 1. Simply use the same code to create the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CDATA(torch.utils.data.Dataset): # Extend PyTorch's Dataset class\n",
    "    def __init__(self, root_dir, train, transform=None):\n",
    "        # root_dir  - the root directory of the dataset\n",
    "        # train     - a boolean parameter representing whether to return the training set or the test set\n",
    "        # transform - the transforms to be applied on the images before returning them\n",
    "        #\n",
    "        # In this function store the parameters in instance variables and make a mapping\n",
    "        # from images to labels and keep it as an instance variable. Make sure to check which\n",
    "        # dataset is required; train or test; and create the mapping accordingly.\n",
    "        self.root_dir = root_dir\n",
    "        self.train = train\n",
    "        self.transform  = transform\n",
    "        self.map = list()\n",
    "        \n",
    "        if(train == True):\n",
    "            rd = root_dir + \"/train/Visible\"\n",
    "        else:\n",
    "            rd = root_dir\n",
    "            \n",
    "        for subdir, dirs, files in os.walk(rd):\n",
    "            for File in files:\n",
    "                lab = int(File.split('_')[0])  \n",
    "                (x, y, w, h) = (int(File.split('_')[1]), int(File.split('_')[2]), int(File.split('_')[3]), int(File.split('_')[4]))              \n",
    "                self.map = self.map + [(File, lab, (x, y, w, h))]\n",
    "                \n",
    "        \n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        # return the size of the dataset (total number of images) as an integer\n",
    "        # this should be rather easy if you created a mapping in __init__\n",
    "        return len(self.map)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # idx - the index of the sample requested\n",
    "        if(self.train==1):\n",
    "            rd = self.root_dir + \"/train\"\n",
    "            ir_img = Image.open(rd + \"/Infrared/\" + self.map[idx][0]).convert('L')\n",
    "            vi_img = Image.open(rd + \"/Visible/\" + self.map[idx][0]).convert('L')\n",
    "            (x, y, w, h) = self.map[idx][2]\n",
    "            ir_img = ir_img.crop((x,y,x+w,y+h))\n",
    "            vi_img = vi_img.crop((x,y,x+w,y+h))\n",
    "            ir_img = ir_img.resize( crop_res, Image.ANTIALIAS)\n",
    "            vi_img = vi_img.resize( crop_res, Image.ANTIALIAS)\n",
    "            ir_img = np.array(ir_img)\n",
    "            vi_img = np.array(vi_img)\n",
    "#             cv2.imshow(\"original image\", vi_img)\n",
    "#             cv2.waitKey(0)\n",
    "\n",
    "#             ir_img = ir_img[y: y+h, x: x+w]\n",
    "#             vi_img = vi_img[y: y+h, x: x+w]\n",
    "#             ir_img = np.resize(ir_img, crop_res)\n",
    "#             vi_img = np.resize(vi_img, crop_res)\n",
    "#             print(\"image_ir\")\n",
    "#             print(ir_img)\n",
    "\n",
    "\n",
    "            stride_1 = windowStride[0]\n",
    "            stride_2 = windowStride[1]\n",
    "            point_set = set((a,b) for a in range(0,crop_res[1] - winSize[1], stride_1) for b in range(0,crop_res[0] - winSize[0],stride_2))\n",
    "    #             print(\"point set len is \"+str(len(point_set)))\n",
    "            ir_projs = np.zeros((len(point_set),pca_dims+2))\n",
    "            vi_projs = np.zeros((len(point_set),pca_dims+2))\n",
    "\n",
    "            j=0\n",
    "            (wi, hi) = winSize\n",
    "            for cx,cy in point_set:\n",
    "#                 area = (cy, cx, cy + winSize[0], cx + winSize[1])\n",
    "                # area_set = area_set + [area]\n",
    "                ir_patch = ir_img[cy:cy+winSize[0], cx:cx+winSize[0]]\n",
    "                vi_patch = vi_img[cy:cy+winSize[0], cx:cx+winSize[0]]\n",
    "#                 print(\"winsize\" + str(winSize))\n",
    "#                 print(ir_patch.shape)\n",
    "                ir_hog = preprocessing(ir_patch) #return row vector\n",
    "                vi_hog = preprocessing(vi_patch)\n",
    "                    # For PCA\n",
    "#                 ir_proj = np.matmul(ir_hog - mu_ir, Wt_ir[:,:pca_dims]) # Wt = np.transpose(PCA(data).Wt[:pca_dims])\n",
    "#                 vi_proj = np.matmul(vi_hog - mu_vi, Wt_vi[:,:pca_dims])\n",
    "                # append x,y \n",
    "                ir_proj = np.append(ir_hog, [np.divide((cy+hi/2, cx+wi/2) - np.divide(crop_res,2), crop_res[0])])\n",
    "                vi_proj = np.append(vi_hog, [np.divide((cy+hi/2, cx+wi/2) - np.divide(crop_res,2), crop_res[0])])\n",
    "                \n",
    "#                 print(\"ir_proj\", ir_proj)\n",
    "                ir_projs[j] = ir_proj\n",
    "                vi_projs[j] = vi_proj\n",
    "                j=j+1\n",
    "    #             ir_projs = np.reshape(ir_projs, (-1, pca_dims))\n",
    "    #             vi_projs = np.reshape(vi_projs, (-1, pca_dims))\n",
    "\n",
    "            ir_projs = torch.from_numpy(ir_projs)\n",
    "            vi_projs = torch.from_numpy(vi_projs)\n",
    "    #             print(vi_projs.shape)\n",
    "            return (vi_projs, ir_projs, self.map[idx][1])\n",
    "    \n",
    "        else:\n",
    "            rd = self.root_dir \n",
    "            img = Image.open(rd + self.map[idx][0]).convert('L')\n",
    "            (x, y, w, h) = self.map[idx][2]\n",
    "            img = img.crop((x,y,x+w,y+h))\n",
    "            img = img.resize( crop_res, Image.ANTIALIAS)\n",
    "            img = np.array(img)\n",
    "            stride_1 = windowStride[0]\n",
    "            stride_2 = windowStride[1]\n",
    "            point_set = set((a,b) for a in range(0,crop_res[1] - winSize[1], stride_1) for b in range(0,crop_res[0] - winSize[0],stride_2))\n",
    "    #             print(\"point set len is \"+str(len(point_set)))\n",
    "            projs = np.zeros((len(point_set),pca_dims+2))\n",
    "            j=0\n",
    "            (wi, hi) = winSize\n",
    "            for cx,cy in point_set:\n",
    "#                 area = (cy, cx, cy + winSize[0], cx + winSize[1])\n",
    "                # area_set = area_set + [area]\n",
    "                \n",
    "                patch = img[cy:cy+winSize[0], cx:cx+winSize[0]]\n",
    "                hog = preprocessing(patch) #return row vector\n",
    "#                 proj = np.matmul(hog - mu_ir, Wt_ir[:,:pca_dims]) # Wt = np.transpose(PCA(data).Wt[:pca_dims])\n",
    "                # append x,y \n",
    "                proj = np.append(hog, [np.divide((cy+hi/2, cx+wi/2) - np.divide(crop_res,2), crop_res[0])])\n",
    "                projs[j] = proj\n",
    "                j=j+1\n",
    "\n",
    "            projs = torch.from_numpy(projs)\n",
    "            \n",
    "    #             print(vi_projs.shape)\n",
    "            return (projs, self.map[idx][1])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "composed_transform = transforms.Compose([transforms.Scale((32,32)),transforms.ToTensor()])\n",
    "train_dataset = CDATA(root_dir='./images', train=True, transform=None) # Supply proper root_dir\n",
    "test_ir_dataset = CDATA(root_dir='./images/test/Infrared/', train=False, transform=None) # Supply proper root_dir\n",
    "test_vi_dataset = CDATA(root_dir='./images/test/Visible/', train=False, transform=None) # Supply proper root_dir\n",
    "test_ir_dataset_tr = CDATA(root_dir='./images/train/Infrared/', train=False, transform=None) # Supply proper root_dir\n",
    "test_vi_dataset_tr = CDATA(root_dir='./images/train/Visible/', train=False, transform=None) # Supply proper root_dir\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_ir_loader = torch.utils.data.DataLoader(dataset=test_ir_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_vi_loader = torch.utils.data.DataLoader(dataset=test_vi_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_ir_loader_tr = torch.utils.data.DataLoader(dataset=test_ir_dataset_tr, batch_size=batch_size, shuffle=False)\n",
    "test_vi_loader_tr = torch.utils.data.DataLoader(dataset=test_vi_dataset_tr, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Custom Network\n",
    "It's time to create a new custom network.  The architecture of the network is provided in the diagram. It specifies the layer names, layer types as well as their parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomDPM(nn.Module): # Extend PyTorch's Module class\n",
    "    def __init__(self, num_classes = 66):\n",
    "        super(CustomDPM, self).__init__() # Must call super __init__()\n",
    "        \n",
    "        # Define the layers of the network here\n",
    "        # There should be 17 total layers as evident from the diagram\n",
    "        # The parameters and names for the layers are provided in the diagram\n",
    "        # The variable names have to be the same as the ones in the diagram\n",
    "        # Otherwise, the weights will not load\n",
    "        self.linear1 = nn.Linear(num_classes,200)\n",
    "        self.lyr1relu1 = nn.ReLU(inplace = True)\n",
    "        self.linear2 = nn.Linear(200,200)\n",
    "        self.lyr1relu2 = nn.ReLU(inplace=True)\n",
    "        self.linear3 = nn.Linear(200,num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.lyr1relu1(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.lyr1relu2(out)\n",
    "        out = self.linear3(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        # Here you have to define the forward pass\n",
    "        # Make sure you take care of the skip connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declare the model\n",
    "Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DPMnet = CustomDPM(num_classes = 1298) # 66 classes \n",
    "\n",
    "# Load CIFAR-100 weights. (Download them from assignment page)\n",
    "# If network was properly implemented, weights should load without any problems\n",
    "# model.load_state_dict(torch.load('./../CIFAR-100_weights')) # Supply the path to the weight file\n",
    "\n",
    "if(torch.cuda.is_available() and use_gpu):\n",
    "    DPMnet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    print(m)\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.uniform(m.weight,-0.1, 0.1)\n",
    "        print(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear (1298 -> 200)\n",
      "Parameter containing:\n",
      " 4.1784e-02 -2.6389e-02  4.2451e-02  ...   4.0140e-03 -2.7281e-02 -8.4952e-02\n",
      " 8.7341e-03  7.5249e-02 -1.5299e-02  ...   8.4703e-02  8.6359e-02 -1.7214e-02\n",
      " 3.5750e-02  2.9859e-02 -1.6151e-02  ...  -5.5684e-03  7.5214e-02  1.9149e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-7.9282e-02 -6.7280e-02  3.6227e-02  ...   8.8882e-05 -4.0478e-02 -4.9369e-02\n",
      " 8.8838e-02 -9.1072e-03  1.1796e-02  ...   7.8317e-03 -6.9704e-02  1.5734e-02\n",
      "-1.4362e-02 -5.3054e-03  3.9006e-02  ...  -1.6507e-02 -1.5038e-02 -4.5264e-02\n",
      "[torch.cuda.FloatTensor of size 200x1298 (GPU 0)]\n",
      "\n",
      "ReLU (inplace)\n",
      "Linear (200 -> 200)\n",
      "Parameter containing:\n",
      "1.00000e-02 *\n",
      " 6.2936 -6.0541  4.0919  ...  -0.5014 -5.1896 -5.2974\n",
      " 8.6116 -5.2603 -7.5723  ...  -6.2156 -3.8014  1.3219\n",
      " 4.9415 -5.2147 -3.6654  ...  -9.9787 -4.2702 -3.3868\n",
      "          ...             ⋱             ...          \n",
      " 3.0307 -9.8553 -8.5486  ...   2.4455 -4.7732 -1.2487\n",
      "-7.4160 -4.6128 -1.2560  ...   7.6859  1.4035 -0.7688\n",
      "-9.4762  6.3099  5.4916  ...   5.4025 -9.9311  8.0353\n",
      "[torch.cuda.FloatTensor of size 200x200 (GPU 0)]\n",
      "\n",
      "ReLU (inplace)\n",
      "Linear (200 -> 1298)\n",
      "Parameter containing:\n",
      " 7.8476e-02  7.7248e-02  9.0466e-02  ...  -5.7977e-02  7.8150e-02  9.8172e-02\n",
      "-9.8031e-02  3.0734e-02  9.2813e-03  ...   6.2100e-02  3.0218e-02 -3.1733e-02\n",
      "-5.2621e-02  2.8198e-02 -4.2624e-02  ...   3.3644e-03 -5.5881e-02 -6.8270e-02\n",
      "                ...                   ⋱                   ...                \n",
      " 6.8625e-02  3.7978e-02 -9.1853e-03  ...   8.1860e-02 -4.8235e-02 -5.7572e-02\n",
      " 8.1925e-02  8.8915e-02 -6.7323e-02  ...  -3.7416e-02 -7.7916e-02  8.0545e-02\n",
      "-6.6543e-02 -2.2749e-02 -3.3856e-02  ...  -9.6231e-02 -1.5810e-02  4.8408e-02\n",
      "[torch.cuda.FloatTensor of size 1298x200 (GPU 0)]\n",
      "\n",
      "CustomDPM (\n",
      "  (linear1): Linear (1298 -> 200)\n",
      "  (lyr1relu1): ReLU (inplace)\n",
      "  (linear2): Linear (200 -> 200)\n",
      "  (lyr1relu2): ReLU (inplace)\n",
      "  (linear3): Linear (200 -> 1298)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomDPM (\n",
       "  (linear1): Linear (1298 -> 200)\n",
       "  (lyr1relu1): ReLU (inplace)\n",
       "  (linear2): Linear (200 -> 200)\n",
       "  (lyr1relu2): ReLU (inplace)\n",
       "  (linear3): Linear (200 -> 1298)\n",
       ")"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DPMnet.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss function and optimizers\n",
    "criterion = nn.MSELoss()# Define MSEentropy loss\n",
    "optimizer = torch.optim.SGD(DPMnet.parameters(), lr=learning_rate, weight_decay= reg_lambda )# Use Adam optimizer, use learning_rate hyper parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Code for training the model\n",
    "    # Make sure to output a matplotlib graph of training losses\n",
    "    x = list()\n",
    "    y = list()\n",
    "    z = list()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (vi_images,ir_images ,labels) in enumerate(train_loader):  \n",
    "#             print(\"hey\")\n",
    "            # Convert torch tensor to Variable\n",
    "#             print(ir_images[0].type)\n",
    "            ir_images = Variable(ir_images[0]).float()\n",
    "            vi_images = Variable(vi_images[0]).float()\n",
    "            if(use_gpu):\n",
    "                ir_images=ir_images.cuda()\n",
    "                vi_images=vi_images.cuda()\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()  # zero the gradient buffer\n",
    "#             print(vi_images.type)\n",
    "            outputs = DPMnet(vi_images)\n",
    "            loss = criterion(outputs, ir_images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#             print(loss.data)\n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \n",
    "                       %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "                x.append((epoch*len(train_dataset))/batch_size + 1+i)\n",
    "                y.append(loss.data[0])\n",
    "                plt.plot(x,y,color = 'red')\n",
    "                plt.title('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \n",
    "                       %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "                plt.xlabel(\"Batch Number\")\n",
    "                plt.ylabel(\"Cross Entropy Loss\")\n",
    "                display.clear_output(wait=True)\n",
    "                display.display(plt.gcf())\n",
    "            #if(i==40):\n",
    "            #    break\n",
    "        #break\n",
    "    plt.savefig('Loss.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWUscSMzMrCUOJGZm1hIHEjMza8n/Bz9ymXE82P7eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd108bfb1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 43s, sys: 1min 18s, total: 9min 2s\n",
      "Wall time: 7min 37s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWUscSMzMrCUOJGZm1hIHEjMza8n/Bz9ymXE82P7eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd108bfb1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%time train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the weights for newly trained model\n",
    "torch.save(DPMnet.state_dict(), 'DPMnet_50_0.0003_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dnet = CustomDPM(num_classes = 1298)\n",
    "if(torch.cuda.is_available() and use_gpu):\n",
    "    Dnet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dnet.load_state_dict(torch.load('DPMnet_50_0.0003_2.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ImageToVec(model, dataset, loader, filename):\n",
    "    image_labels = list()\n",
    "    num_images = dataset.__len__()\n",
    "    print(num_images)\n",
    "    image_mat = np.zeros((num_images, num_patches_per_image*(hog_size+2) ))\n",
    "    for i, (images ,labels) in enumerate(loader):  \n",
    "        # Convert torch tensor to Variable\n",
    "        images = Variable(images[0]).float()\n",
    "        if(use_gpu):\n",
    "            images=images.cuda()\n",
    "        # Forward + Backward + Optimize        \n",
    "        outputs = model(images)\n",
    "        image_patches = outputs.data.cpu().numpy()\n",
    "        image_vec = np.reshape(image_patches, (1, -1)) #flatten the patches into a 1d vector\n",
    "        image_mat[i] = image_vec\n",
    "        image_labels = image_labels + [labels[0]]\n",
    "        print(i)\n",
    "    image_labels = np.array(image_labels).astype(int)\n",
    "    np.savetxt(filename + '_mat.txt', image_mat)\n",
    "    np.savetxt(filename + '_labels.txt', image_labels)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "CPU times: user 19 s, sys: 588 ms, total: 19.6 s\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%time ImageToVec(Dnet, test_vi_dataset, test_vi_loader, \"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image_mat = np.loadtxt('image_mat.txt',dtype=np.float32)\n",
    "# image_labels = np.loadtxt('image_labels.txt', dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# img_mat_norm = LA.norm(image_mat, axis=1).reshape((-1,1))\n",
    "# n_img_mat = np.divide(image_mat, img_mat_norm)\n",
    "# print(img_mat_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_weights = torch.load('DPMnet_50_0.0003.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear1.weight', \n",
      " 3.9179e-02 -8.3132e-02  5.0568e-03  ...  -4.0279e-02  6.7216e-02  2.3972e-02\n",
      "-4.4562e-02 -3.8204e-02  2.9851e-02  ...   6.4912e-02 -8.2164e-02  6.3330e-02\n",
      " 1.4037e-02 -1.7900e-02  1.5465e-02  ...   6.3803e-03 -6.4747e-02  5.9897e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-6.4881e-02  6.6055e-02  4.7231e-02  ...  -4.2722e-02  7.0227e-02 -1.5397e-02\n",
      " 8.7685e-03 -5.0644e-03 -2.2826e-02  ...   2.3638e-02  5.0757e-02  4.8623e-02\n",
      "-4.3591e-02 -3.4707e-02 -4.8007e-02  ...  -3.0646e-02  2.6630e-02  6.5219e-02\n",
      "[torch.cuda.FloatTensor of size 200x1298 (GPU 0)]\n",
      "), ('linear1.bias', \n",
      "1.00000e-02 *\n",
      " -0.8838\n",
      "  0.9953\n",
      "  1.6252\n",
      " -0.6679\n",
      " -3.1303\n",
      "  0.5518\n",
      " -3.1998\n",
      " -4.0425\n",
      "  1.1778\n",
      " -1.5447\n",
      " -0.2594\n",
      " -1.7771\n",
      "  1.2098\n",
      "  0.5935\n",
      " -2.2161\n",
      "  1.7138\n",
      "  2.3254\n",
      "  2.4096\n",
      "  1.2606\n",
      "  0.9372\n",
      " -0.7406\n",
      " -2.8326\n",
      "  2.0533\n",
      "  0.1544\n",
      "  1.8228\n",
      " -1.8553\n",
      " -2.8161\n",
      " -3.3940\n",
      "  1.7690\n",
      " -0.4521\n",
      " -1.3498\n",
      " -2.5588\n",
      "  3.0573\n",
      " -0.7261\n",
      " -0.3824\n",
      " -1.4826\n",
      " -2.3704\n",
      "  2.6968\n",
      "  0.8690\n",
      " -0.7438\n",
      "  1.7164\n",
      "  0.3686\n",
      " -1.5709\n",
      " -3.0856\n",
      " -3.7753\n",
      " -0.2116\n",
      "  0.3521\n",
      " -1.9776\n",
      "  1.7010\n",
      "  1.9198\n",
      "  0.1615\n",
      "  1.9699\n",
      " -1.0130\n",
      " -0.8916\n",
      "  1.5617\n",
      " -0.3670\n",
      "  0.0287\n",
      " -2.8233\n",
      " -2.1440\n",
      "  0.4540\n",
      "  0.5677\n",
      " -1.5694\n",
      " -1.0333\n",
      " -3.9748\n",
      " -1.3200\n",
      "  1.8739\n",
      "  0.6096\n",
      "  1.0733\n",
      "  1.9298\n",
      " -2.2382\n",
      " -0.5398\n",
      " -0.3735\n",
      " -1.0904\n",
      " -0.9113\n",
      " -0.4992\n",
      "  2.5227\n",
      "  0.8100\n",
      " -1.4693\n",
      "  2.9109\n",
      "  1.1448\n",
      " -1.6564\n",
      "  0.7660\n",
      " -1.5140\n",
      " -1.3012\n",
      " -1.0900\n",
      "  1.8243\n",
      " -1.6250\n",
      " -2.0383\n",
      "  0.8100\n",
      "  0.3901\n",
      " -0.7637\n",
      " -2.0191\n",
      " -1.4841\n",
      " -0.0771\n",
      " -3.4211\n",
      " -0.4138\n",
      "  1.8465\n",
      " -1.3900\n",
      "  2.1651\n",
      " -0.5132\n",
      " -1.7541\n",
      " -2.6260\n",
      " -2.0117\n",
      " -0.5724\n",
      " -0.6710\n",
      "  2.0843\n",
      "  2.3439\n",
      " -0.8989\n",
      "  0.4683\n",
      " -1.9139\n",
      " -1.9932\n",
      " -2.4219\n",
      " -0.6066\n",
      " -1.8764\n",
      " -0.7226\n",
      "  1.8263\n",
      "  1.1327\n",
      " -0.5321\n",
      "  0.4430\n",
      "  2.0106\n",
      " -1.7752\n",
      "  0.1949\n",
      " -1.3073\n",
      " -1.9556\n",
      " -2.7707\n",
      " -1.6835\n",
      "  1.8950\n",
      " -1.0470\n",
      " -1.3466\n",
      "  1.7748\n",
      "  1.7566\n",
      " -3.1986\n",
      " -3.0230\n",
      " -0.1161\n",
      "  0.6550\n",
      "  1.3276\n",
      "  0.0323\n",
      " -0.3425\n",
      "  1.3398\n",
      " -2.2176\n",
      " -2.2588\n",
      " -4.3879\n",
      " -0.7201\n",
      "  1.3123\n",
      "  2.9773\n",
      "  1.0008\n",
      " -1.9218\n",
      "  0.4352\n",
      " -1.8588\n",
      " -1.8766\n",
      "  0.0965\n",
      " -2.5720\n",
      "  0.9274\n",
      "  0.3764\n",
      "  0.5033\n",
      " -0.0084\n",
      "  0.6824\n",
      " -0.7627\n",
      " -2.2402\n",
      "  1.2309\n",
      " -3.4770\n",
      "  1.1981\n",
      "  2.1164\n",
      "  4.3145\n",
      " -0.4957\n",
      " -1.4090\n",
      " -0.5252\n",
      "  1.9361\n",
      " -0.5346\n",
      "  2.0042\n",
      "  0.4981\n",
      "  2.7699\n",
      " -1.2874\n",
      "  0.5684\n",
      "  0.6901\n",
      "  0.2491\n",
      "  0.4672\n",
      " -3.1707\n",
      " -0.8769\n",
      " -0.3875\n",
      "  0.2932\n",
      " -0.7721\n",
      " -0.9941\n",
      "  1.2348\n",
      " -1.2436\n",
      " -0.8662\n",
      " -1.8970\n",
      " -1.0331\n",
      "  1.0286\n",
      " -1.5650\n",
      " -0.6047\n",
      " -1.8839\n",
      " -1.0744\n",
      "  1.6389\n",
      " -2.3484\n",
      " -0.9868\n",
      " -2.3304\n",
      " -0.5164\n",
      " -0.7393\n",
      " -1.7283\n",
      "[torch.cuda.FloatTensor of size 200 (GPU 0)]\n",
      "), ('linear2.weight', \n",
      " 7.1914e-02  5.4209e-02 -2.3490e-02  ...   1.7161e-02 -5.8293e-02 -8.7456e-02\n",
      " 5.5818e-02  1.7871e-02  2.7767e-03  ...  -7.9907e-02 -4.5943e-02 -8.8026e-02\n",
      "-8.3103e-02  6.8688e-02  8.8252e-02  ...  -3.2950e-02  3.8993e-03 -5.1099e-02\n",
      "                ...                   ⋱                   ...                \n",
      " 7.0372e-02 -1.9396e-02  2.4159e-03  ...  -8.8816e-02  4.4494e-02 -1.4552e-02\n",
      " 4.5304e-02  6.3911e-02 -4.3246e-02  ...   5.6233e-02 -3.0775e-02 -2.5459e-02\n",
      " 5.3898e-02  3.7328e-02 -6.1626e-02  ...  -7.6780e-02 -5.4583e-04  2.8918e-02\n",
      "[torch.cuda.FloatTensor of size 200x200 (GPU 0)]\n",
      "), ('linear2.bias', \n",
      " 0.0307\n",
      " 0.0426\n",
      "-0.0216\n",
      " 0.0118\n",
      "-0.0418\n",
      "-0.0487\n",
      " 0.0236\n",
      "-0.0258\n",
      " 0.0563\n",
      " 0.0130\n",
      "-0.0101\n",
      "-0.0148\n",
      "-0.0409\n",
      " 0.0566\n",
      " 0.0224\n",
      " 0.0066\n",
      "-0.0012\n",
      "-0.0162\n",
      "-0.0262\n",
      " 0.0070\n",
      " 0.0114\n",
      " 0.0568\n",
      "-0.0276\n",
      "-0.0304\n",
      "-0.0264\n",
      "-0.0508\n",
      " 0.0261\n",
      "-0.0338\n",
      "-0.0498\n",
      "-0.0137\n",
      "-0.0384\n",
      "-0.0397\n",
      "-0.0500\n",
      "-0.0270\n",
      "-0.0402\n",
      " 0.0095\n",
      " 0.0351\n",
      " 0.0187\n",
      " 0.0154\n",
      " 0.0420\n",
      " 0.0395\n",
      "-0.0136\n",
      "-0.0542\n",
      "-0.0435\n",
      " 0.0429\n",
      "-0.0300\n",
      "-0.0703\n",
      " 0.0394\n",
      "-0.0283\n",
      " 0.0468\n",
      "-0.1000\n",
      "-0.0276\n",
      "-0.0382\n",
      "-0.0441\n",
      " 0.0383\n",
      " 0.0329\n",
      "-0.0641\n",
      " 0.0065\n",
      " 0.0096\n",
      " 0.0315\n",
      " 0.0035\n",
      " 0.0636\n",
      " 0.0114\n",
      " 0.0482\n",
      "-0.0213\n",
      "-0.0340\n",
      " 0.0215\n",
      "-0.0149\n",
      "-0.0042\n",
      "-0.0453\n",
      "-0.0299\n",
      " 0.0298\n",
      "-0.0619\n",
      " 0.0422\n",
      "-0.0122\n",
      "-0.0513\n",
      " 0.0106\n",
      "-0.0191\n",
      "-0.0473\n",
      "-0.0397\n",
      " 0.0567\n",
      "-0.0030\n",
      "-0.0497\n",
      "-0.0275\n",
      "-0.0337\n",
      "-0.0262\n",
      " 0.0358\n",
      "-0.0209\n",
      "-0.0633\n",
      "-0.0607\n",
      " 0.0734\n",
      "-0.0177\n",
      "-0.0353\n",
      "-0.0373\n",
      " 0.0320\n",
      "-0.0117\n",
      "-0.0230\n",
      " 0.0008\n",
      "-0.0076\n",
      " 0.0592\n",
      " 0.0271\n",
      " 0.0040\n",
      "-0.0153\n",
      "-0.0227\n",
      "-0.0105\n",
      "-0.0618\n",
      "-0.0599\n",
      "-0.0647\n",
      "-0.0279\n",
      " 0.0005\n",
      " 0.0206\n",
      "-0.0064\n",
      " 0.0167\n",
      "-0.0312\n",
      "-0.0531\n",
      " 0.0155\n",
      " 0.0056\n",
      "-0.0347\n",
      " 0.0207\n",
      "-0.0161\n",
      " 0.0391\n",
      " 0.0202\n",
      " 0.0166\n",
      "-0.0028\n",
      " 0.0701\n",
      " 0.0200\n",
      "-0.0191\n",
      "-0.0482\n",
      "-0.0438\n",
      "-0.0243\n",
      " 0.0306\n",
      "-0.0246\n",
      "-0.0084\n",
      "-0.0242\n",
      "-0.0193\n",
      "-0.1028\n",
      "-0.0235\n",
      "-0.0759\n",
      " 0.0310\n",
      "-0.0608\n",
      "-0.0375\n",
      "-0.0748\n",
      "-0.0222\n",
      "-0.0070\n",
      "-0.0480\n",
      "-0.0167\n",
      "-0.0365\n",
      "-0.0419\n",
      "-0.0679\n",
      " 0.0359\n",
      "-0.0022\n",
      "-0.0476\n",
      " 0.0372\n",
      " 0.0303\n",
      " 0.0466\n",
      "-0.0554\n",
      " 0.0207\n",
      "-0.0295\n",
      "-0.0657\n",
      "-0.0370\n",
      "-0.0469\n",
      " 0.0150\n",
      " 0.0107\n",
      " 0.0574\n",
      "-0.0124\n",
      "-0.0256\n",
      " 0.0247\n",
      "-0.0232\n",
      "-0.0102\n",
      "-0.0254\n",
      " 0.0064\n",
      " 0.0101\n",
      " 0.0281\n",
      "-0.0156\n",
      "-0.0387\n",
      " 0.0263\n",
      "-0.0222\n",
      "-0.0283\n",
      " 0.0471\n",
      "-0.0005\n",
      "-0.0997\n",
      "-0.0126\n",
      "-0.0175\n",
      "-0.0176\n",
      " 0.0546\n",
      " 0.0059\n",
      "-0.0153\n",
      " 0.0062\n",
      "-0.0043\n",
      "-0.0560\n",
      "-0.0638\n",
      " 0.0446\n",
      " 0.0222\n",
      " 0.0472\n",
      "-0.0812\n",
      " 0.0090\n",
      "-0.0089\n",
      "-0.0177\n",
      " 0.0702\n",
      "-0.0376\n",
      "[torch.cuda.FloatTensor of size 200 (GPU 0)]\n",
      "), ('linear3.weight', \n",
      " 3.1114e-02 -8.7092e-02  8.9916e-02  ...   3.8416e-02  3.1838e-02 -7.7168e-02\n",
      "-2.8748e-02  3.4224e-02  3.6261e-02  ...   1.7162e-02  1.8169e-02  2.4691e-02\n",
      " 8.8635e-02 -4.8314e-02  5.4143e-02  ...  -7.2944e-02  1.9464e-02  2.8557e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-7.3788e-02 -3.1199e-02 -6.5096e-02  ...   5.3642e-02  1.2328e-02  2.1840e-02\n",
      "-1.6124e-03  2.2278e-03  6.0031e-02  ...   2.4817e-02 -6.1293e-03 -7.2134e-02\n",
      " 2.6280e-02 -3.7618e-02 -6.6120e-02  ...   1.0401e-02 -4.6160e-02  2.0447e-02\n",
      "[torch.cuda.FloatTensor of size 1298x200 (GPU 0)]\n",
      "), ('linear3.bias', \n",
      "-1.5444e-02\n",
      " 2.5473e-02\n",
      "-1.9311e-02\n",
      "     ⋮     \n",
      " 2.1529e-02\n",
      " 2.1516e-02\n",
      " 1.2170e-02\n",
      "[torch.cuda.FloatTensor of size 1298 (GPU 0)]\n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "print(net_weights)\n",
    "# for param in DPMnet.parameters():\n",
    "#     print(param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test( dataset, loader, filename):\n",
    "    # Write loops for testing the model on the test set\n",
    "    # You should also print out the accuracy of the model\n",
    "    image_labels = list()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    num_images = dataset.__len__()\n",
    "    image_mat = np.zeros((num_images, num_patches_per_image*(hog_size+2) ))\n",
    "    \n",
    "    for i,(images, labels) in enumerate(loader):\n",
    "        images = images[0].numpy()\n",
    "        print(i)\n",
    "        image_vec = np.reshape(images, (1, -1)) #flatten the patches into a 1d vector\n",
    "        image_mat[i] = image_vec\n",
    "        image_labels = image_labels + [labels[0]]\n",
    "    \n",
    "    image_data = np.loadtxt(filename + '_mat.txt',dtype=np.float32)\n",
    "    image_data_labels = np.loadtxt(filename + '_labels.txt', dtype=np.int32)\n",
    "    print(\"train set loaded\")\n",
    "    img_mat_norm = LA.norm(image_mat, axis=1).reshape((-1,1))\n",
    "    n_img_mat = np.divide(image_mat, img_mat_norm)\n",
    "    y = np.matmul(n_img_mat, np.transpose(image_data))\n",
    "    np.savetxt('dot-product.txt',y)\n",
    "    predicted = image_data_labels[np.argmax(y, axis=1)]\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "    np.savetxt(filename + '_predictions.txt', predicted)\n",
    "    np.savetxt(filename + '_test_labels.txt', image_labels)\n",
    "    total = num_images\n",
    "    correct = (predicted == image_labels).sum()\n",
    "    print('Accuracy of the network on the images: %d %%' % (100 * correct/total ))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "train set loaded\n",
      "Accuracy of the network on the images: 3 %\n",
      "CPU times: user 26.6 s, sys: 1.02 s, total: 27.6 s\n",
      "Wall time: 26.4 s\n"
     ]
    }
   ],
   "source": [
    "#test the retrained model\n",
    "%time test(test_ir_dataset, test_ir_loader, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training from scratch\n",
    "Now we shall try training the model from scratch and observe the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1159\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "CPU times: user 42.4 s, sys: 884 ms, total: 43.2 s\n",
      "Wall time: 46 s\n"
     ]
    }
   ],
   "source": [
    "%time ImageToVec(Dnet, test_vi_dataset_tr, test_vi_loader_tr, \"train_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "train set loaded\n",
      "Accuracy of the network on the images: 1 %\n",
      "CPU times: user 1min 4s, sys: 2.85 s, total: 1min 7s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "#test the  model on training data\n",
    "%time test(test_ir_dataset_tr, test_ir_loader_tr, \"train_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reinstantiate the model and optimizer\n",
    "# model = CustomResnet(num_classes = 10)\n",
    "# optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)# Use Adam optimizer, use learning_rate hyper parameter\n",
    "# print(torch.cuda.is_available)\n",
    "# if(torch.cuda.is_available() and use_gpu):\n",
    "#     model.cuda()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the weights for newly trained model\n",
    "# torch.save(DPMnet.state_dict(), 'DPMnet_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 92 %\n",
      "CPU times: user 732 ms, sys: 60 ms, total: 792 ms\n",
      "Wall time: 789 ms\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "# %time test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of Assignment 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
